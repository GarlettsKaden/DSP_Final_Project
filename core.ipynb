{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3616281",
   "metadata": {},
   "source": [
    "### Kaden Garletts\n",
    "### Date start: August 5th 2025, Date due: August 19th 2025 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e35a5a1",
   "metadata": {},
   "source": [
    "  In core.ipynb, the conduction of webscraping of www.hackettstownbid.com, is used to perform Data Analysis used to answer several questions related to the planning of hackettstown busnisses, and to identify potential factors in business decisions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b758232a",
   "metadata": {},
   "source": [
    "### The questions:\n",
    "1. What type of businesses are the most popular in Hackettstown? \"(ie. count per category compared to other categories)\n",
    "\n",
    "2. Which types are the least popular?\n",
    "\n",
    "3. Which businesses are closest to eachother\n",
    "\n",
    "4. Which businesses are closest to the main roads\n",
    "\n",
    "5. Which busineses are closest to businesses of related types? (using google maps API for matrix distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eccb92",
   "metadata": {},
   "source": [
    "# Part 0.2: Exploratory Analysis of the Dataset Milestone #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3f9a5d",
   "metadata": {},
   "source": [
    "1. Becuase I chose to webscrape, its far harder to perform exploratory data analysis. \n",
    "\n",
    "a.describe(): There will not be a mean,std,min, or IQR --> but there will be the distance matrix\n",
    "\n",
    "b.columns(): The columns are Restaurants, Community, Services, Shopping, and Entertainment/Gaming which have, names, and locations for rows\n",
    "\n",
    "c.shape(): The shape of the data should be in 3 dimensions, as each row will be a list with name, and location\n",
    "\n",
    "d.dtypes(): The datatypes should be float and string \n",
    "\n",
    "e.head(),tail(),sample() an example would be 'Mama's Cafe Baci', 40.8380252,-74.8263654 \n",
    "\n",
    "f.info() 2 columns, x rows (probably ~50 per table) string, and float variable types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83403ca4",
   "metadata": {},
   "source": [
    "# Part 0.3: Data Cleaning Report MileStone #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ead8fe",
   "metadata": {},
   "source": [
    "For the first part of cleaning the data, I attempted to retrieve all of the names from each of the websites using beautiful soup. The first error I encountered when analysing my data was that there were missing names when I expected otherwise. To solve this I went into the HTML, and discovered that there were discrepancies on wether strong> tags were used or b> was used although they appeared the same. Solving this allowed for the full collection of names. \n",
    "\n",
    "Secondly, the adresses of each location are stored in the HTML aswell. I had issues reaching this one becuase they were stored in basic hyperlink tags without a coordinated identifier. I could have selected all of the hyper-links from an upper class, but It was diffiucult to access as all of the sub-classes had varying names. I discovered that becuase all of the sub-classes were similar in that they ended with thisClassx where x was a different number I could just iterate through every single class in order to store the links in a list. \n",
    "\n",
    "Further, the links are not what I needed, but rather the location, the initial plan was to just retrieve the coordiinates using the google map HTML, but I discovered that the extended link contains the coordinates. The issue is that the HackettstownBID website only provides the shortened link. To solve this, I am using requests to retrive the full URL from Google, but I am currently attempting to collect the data in a way that Google considers to not be bot activity. \n",
    "\n",
    "Afterwords, I will compare the length of the retirved data to the names to see if everything was collected appropriatly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0492912",
   "metadata": {},
   "source": [
    "### Part 1: Webscraping https://hackettstownbid.com, and performing identifying measures to determine the categorization of businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c3e44d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project imports\n",
    "\n",
    "from bs4 import BeautifulSoup #| beautifulsoup4 used for parsing HTML\n",
    "import requests as req #| requests used for making HTTP requests\n",
    "import re #| re used for regular expressions\n",
    "import seaborn as sns #| seaborn used for data visualization\n",
    "import matplotlib.pyplot as plt #| matplotlib used for plotting graphs\n",
    "import pandas as pd #| pandas used for data manipulation and analysis\n",
    "import numpy as np #| numpy used for numerical operations\n",
    "from geopy.distance import geodesic, great_circle #used to calculate geo-distance\n",
    "import time #| used to pause the system breifly\n",
    "from dotenv import load_dotenv # used to store sensitive info\n",
    "import os #| Used to interact with the operating system\n",
    "import pickle #| used to store data between runs\n",
    "import random\n",
    "\n",
    "load_dotenv() #loading sensitive info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39828f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project URL's\n",
    "\n",
    "urlHackettstownResaurants = \"https://hackettstownbid.com/explore/restaurants/\"\n",
    "urlHackettstownServices = \"https://hackettstownbid.com/explore/services/\"\n",
    "urlHackettstownShopping = \"https://hackettstownbid.com/explore/shopping/\"\n",
    "urlHackettstownEntertainmentGaming = \"https://hackettstownbid.com/explore/entertainment-gaming/\"\n",
    "urlHackettstownCommunity = \"https://hackettstownbid.com/explore/community/\"\n",
    "\n",
    "# Any businesses that are not included on the above pages are not registred with the Hackettstown Business Improvement Discrict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd698d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using requests to fetch the HTML content of the pages\n",
    "\n",
    "responseHackettstownResaurants = req.get(urlHackettstownResaurants)\n",
    "responseHackettstownServices = req.get(urlHackettstownServices)\n",
    "responseHackettstownShopping = req.get(urlHackettstownShopping)\n",
    "responseHackettstownEntertainmentGaming = req.get(urlHackettstownEntertainmentGaming)\n",
    "responseHackettstownCommunity = req.get(urlHackettstownCommunity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the html content into text through requests .text object\n",
    "\n",
    "htmlContentHackettstownResaurants = responseHackettstownResaurants.text\n",
    "htmlContentHackettstownServices = responseHackettstownServices.text\n",
    "htmlContentHackettstownShopping = responseHackettstownShopping.text\n",
    "htmlContentHackettstownEntertainmentGaming = responseHackettstownEntertainmentGaming.text\n",
    "htmlContentHackettstownCommunity = responseHackettstownCommunity.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa82be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating BeautifulSoup objects for each html\n",
    "soupHackettstownRestaurants = BeautifulSoup(htmlContentHackettstownResaurants, 'html.parser')\n",
    "soupHackettstownServices = BeautifulSoup(htmlContentHackettstownServices, 'html.parser')\n",
    "soupHackettstownShopping = BeautifulSoup(htmlContentHackettstownShopping, 'html.parser')\n",
    "soupHackettstownEntertainmentGaming = BeautifulSoup(htmlContentHackettstownEntertainmentGaming, 'html.parser')\n",
    "soupHackettstownCommunity = BeautifulSoup(htmlContentHackettstownCommunity, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f7990",
   "metadata": {},
   "source": [
    "# Part 2: Extracting the content and storing the data into dataframe/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the names of the businesses from the HTML content\n",
    "\n",
    "\n",
    "def getBusinessNames(soupHackettstown):\n",
    "    # https://stackoverflow.com/questions/68144219/how-to-scrape-text-from-strong-tag used to learn how to scrape from a strong tag\n",
    "    strongHackettstown = [[i.get_text(strip=True) for i in div.find_all(\"strong\")]\n",
    "        for div in soupHackettstown.find_all(\n",
    "            \"div\",\n",
    "            class_=\"fusion-column-wrapper fusion-column-has-shadow fusion-flex-justify-content-flex-start fusion-content-layout-column\"\n",
    "        )]\n",
    "    bHackettstown = [[i.get_text(strip=True) for i in div.find_all(\"b\")]\n",
    "        for div in soupHackettstown.find_all(\n",
    "            \"div\",\n",
    "            class_=\"fusion-column-wrapper fusion-column-has-shadow fusion-flex-justify-content-flex-start fusion-content-layout-column\"\n",
    "        )]\n",
    "    strongHackettstown = [hList for hList in strongHackettstown if hList] #Assigns the var to only items that are lists\n",
    "    strongHackettstown.pop(0) # Removes the first item which says \"call us\"\n",
    "    bHackettstown = [hList for hList in bHackettstown if hList]\n",
    "    bHackettstown.pop(0)\n",
    "    namesHackettstown = [item for slist in strongHackettstown for item in slist] + [item for slist in bHackettstown for item in slist]\n",
    "    return namesHackettstown\n",
    "\n",
    "namesHackettstownRestaurants = getBusinessNames(soupHackettstownRestaurants)\n",
    "namesHackettstownCommunity = getBusinessNames(soupHackettstownCommunity)\n",
    "namesHackettstownEntertainmentGaming = getBusinessNames(soupHackettstownEntertainmentGaming)    \n",
    "namesHackettstownServices = getBusinessNames(soupHackettstownServices)\n",
    "namesHackettstownShopping = getBusinessNames(soupHackettstownShopping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5f5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickle...\n",
      "Loading pickle...\n",
      "Loading pickle...\n",
      "Could not find file... attempting to retreive data\n",
      "Attempting session\n",
      "Attempting Head\n",
      "Attempt resp.url\n",
      "1\n",
      "Attempting session\n",
      "Attempting Head\n",
      "Attempt resp.url\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 93\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhackettstown_locations_services.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading pickle...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hackettstown_locations_services.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find file... attempting to retreive data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m     locationHackettstownServices \u001b[38;5;241m=\u001b[39m \u001b[43mgetBusinessLocations\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoupHackettstownServices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData retrieved! now adding to collection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhackettstown_locations_services.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn[15], line 40\u001b[0m, in \u001b[0;36mgetBusinessLocations\u001b[1;34m(soupHackettstown)\u001b[0m\n\u001b[0;32m     38\u001b[0m linksHackettstown[i] \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39murl\n\u001b[0;32m     39\u001b[0m randTime \u001b[38;5;241m=\u001b[39m (random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandTime\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Sleep to avoid Google getting mad...\u001b[39;00m\n\u001b[0;32m     41\u001b[0m countTo49 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     42\u001b[0m countTo100 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Extracts the links of the businesses locations from the HTML\n",
    "\n",
    "def getBusinessLocations(soupHackettstown):\n",
    "    fusionTextNumber = 1  # increments for the naming convention of the divs\n",
    "    classHackettstown = []  # List to store the divs with the class fusion-text-fusionTextNumber\n",
    "    linksHackettstown = []  # List to store the links\n",
    "    soupIteration = True\n",
    "\n",
    "    while soupIteration:\n",
    "        classHackettstown.append(\n",
    "            soupHackettstown.find_all(\n",
    "                \"div\", {\"class\": \"fusion-text fusion-text-\" + str(fusionTextNumber)}\n",
    "            )\n",
    "        )  # Finds all divs with the class fusion-text-fusionTextNumber\n",
    "        fusionTextNumber += 1  # Increments the fusionTextNumber to find the next div\n",
    "        if fusionTextNumber >= 20:\n",
    "            if (\n",
    "                classHackettstown[-1] == []\n",
    "                and classHackettstown[-2] == []\n",
    "                and classHackettstown[-3] == []\n",
    "            ):  # If the last three items in classHackettstown are empty the loop ends\n",
    "                soupIteration = False\n",
    "\n",
    "    # Flatten the list of lists into a single list\n",
    "    classHackettstown = [item for sublist in classHackettstown for item in sublist]\n",
    "\n",
    "    for i in classHackettstown:\n",
    "        linkTags = i.find_all(\"a\")  # Finds all <a> tags in the divs\n",
    "        for j in linkTags:  # Iterates through each <a> tag\n",
    "            href = j.get(\"href\")  # Gets the href attribute of the <a> tag\n",
    "            if href and (\n",
    "                href.startswith(\"https://goo.gl/maps/\")\n",
    "                or href.startswith(\"https://maps.app.goo.gl/\")\n",
    "            ):  # Checks if the link starts with the Google Maps URL\n",
    "                linksHackettstown.append(href)  # Adds the link to the list if it does\n",
    "\n",
    "    # Used to extend the URLs that are shortened by the hyperlinks\n",
    "    # I was able to do this thanks to Stack Overflow\n",
    "\n",
    "    # splitting the links to make storage easier...\n",
    "    if len(linksHackettstown) > 100:\n",
    "        linksTo100 = linksHackettstown[:100]\n",
    "        linksPast100 = linksHackettstown[100:]\n",
    "        # We'll create pickles for these after expansion if missing (see below)\n",
    "\n",
    "    countTo49 = 0\n",
    "    countTo100 = 0\n",
    "    countLocationsCaptured = 0\n",
    "    randTime = (random.random() + 3)\n",
    "\n",
    "    for i in range(len(linksHackettstown)):\n",
    "        print(\"Attempting session\")\n",
    "        session = req.Session()  # so connections are recycled\n",
    "        print(\"Attempting Head\")\n",
    "        try:\n",
    "            resp = session.head(linksHackettstown[i], allow_redirects=True, timeout=30)\n",
    "            print(\"Attempt resp.url\")\n",
    "            linksHackettstown[i] = resp.url\n",
    "        except Exception as e:\n",
    "            # If head fails, keep the original short link so you can inspect later\n",
    "            print(f\"Head failed for index {i} ({linksHackettstown[i]}): {e}\")\n",
    "            # don't overwrite the entry; leave it as-is (short link)\n",
    "        randTime = (random.random() + 3)\n",
    "        time.sleep(randTime)  # Sleep to avoid Google getting mad...\n",
    "        countTo49 += 1\n",
    "        countTo100 += 1\n",
    "        countLocationsCaptured += 1\n",
    "        print(countLocationsCaptured)\n",
    "        if countTo49 == 20:\n",
    "            print(\"sleeping for batch pause\")\n",
    "            time.sleep(125 + randTime)\n",
    "            countTo49 = 0\n",
    "        if countTo100 == 100:\n",
    "            print(\"sleeping for 100 pause\")\n",
    "            time.sleep(300 + randTime)\n",
    "            countTo100 = 0\n",
    "\n",
    "    # After expanding all links, if >100 split into two service pickles (create only if missing)\n",
    "    if len(linksHackettstown) > 100:\n",
    "        svc1_file = \"hackettstown_locations_services1.pkl\"\n",
    "        svc2_file = \"hackettstown_locations_services2.pkl\"\n",
    "        linksTo100 = linksHackettstown[:100]\n",
    "        linksPast100 = linksHackettstown[100:]\n",
    "\n",
    "        # create services1 if it does not exist\n",
    "        try:\n",
    "            with open(svc1_file, \"rb\") as f:\n",
    "                # exists already — leave it\n",
    "                pass\n",
    "        except FileNotFoundError:\n",
    "            try:\n",
    "                with open(svc1_file, \"wb\") as f:\n",
    "                    pickle.dump(linksTo100, f)\n",
    "                print(f\"Saved first 100 links to {svc1_file}\")\n",
    "            except Exception as e:\n",
    "                print(\"Failed to save services1 pickle:\", e)\n",
    "\n",
    "        # create services2 if it does not exist\n",
    "        try:\n",
    "            with open(svc2_file, \"rb\") as f:\n",
    "                # exists already — leave it\n",
    "                pass\n",
    "        except FileNotFoundError:\n",
    "            try:\n",
    "                with open(svc2_file, \"wb\") as f:\n",
    "                    pickle.dump(linksPast100, f)\n",
    "                print(f\"Saved remaining links to {svc2_file}\")\n",
    "            except Exception as e:\n",
    "                print(\"Failed to save services2 pickle:\", e)\n",
    "\n",
    "    time.sleep(20 + randTime)\n",
    "    print(\"Sleeping\")\n",
    "    return linksHackettstown\n",
    "\n",
    "\n",
    "# Attempting to load the pickle, and if it does not --> function call\n",
    "try:\n",
    "    with open(\"hackettstown_locations_restaurants.pkl\", \"rb\") as f:\n",
    "        print(\"Loading pickle...\")\n",
    "        locationHackettstownRestaurants = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find file... attempting to retrieve data\")\n",
    "    locationHackettstownRestaurants = getBusinessLocations(soupHackettstownRestaurants)\n",
    "    print(\"Data retrieved! now adding to collection\")\n",
    "    with open(\"hackettstown_locations_restaurants.pkl\", \"wb\") as f:\n",
    "        pickle.dump(locationHackettstownRestaurants, f)\n",
    "\n",
    "try:\n",
    "    with open(\"hackettstown_locations_community.pkl\", \"rb\") as f:\n",
    "        print(\"Loading pickle...\")\n",
    "        locationHackettstownCommunity = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find file... attempting to retrieve data\")\n",
    "    locationHackettstownCommunity = getBusinessLocations(soupHackettstownCommunity)\n",
    "    print(\"Data retrieved! now adding to collection\")\n",
    "    with open(\"hackettstown_locations_community.pkl\", \"wb\") as f:\n",
    "        pickle.dump(locationHackettstownCommunity, f)\n",
    "\n",
    "try:\n",
    "    with open(\"hackettstown_locations_entertainmentgaming.pkl\", \"rb\") as f:\n",
    "        print(\"Loading pickle...\")\n",
    "        locationHackettstownEntertainmentGaming = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find file... attempting to retrieve data\")\n",
    "    locationHackettstownEntertainmentGaming = getBusinessLocations(soupHackettstownEntertainmentGaming)\n",
    "    print(\"Data retrieved! now adding to collection\")\n",
    "    with open(\"hackettstown_locations_entertainmentgaming.pkl\", \"wb\") as f:\n",
    "        pickle.dump(locationHackettstownEntertainmentGaming, f)\n",
    "\n",
    "# SERVICES: attempt to load services1, if missing call getBusinessLocations once and create the missing pickles\n",
    "all_services = None\n",
    "\n",
    "try:\n",
    "    with open(\"hackettstown_locations_services1.pkl\", \"rb\") as f:\n",
    "        print(\"Loading services1 pickle...\")\n",
    "        locationHackettstownServices1 = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"services1 pickle missing; retrieving services links now...\")\n",
    "    all_services = getBusinessLocations(soupHackettstownServices)\n",
    "    # try to load services1 again (function may have created it), otherwise create from all_services\n",
    "    try:\n",
    "        with open(\"hackettstown_locations_services1.pkl\", \"rb\") as f:\n",
    "            locationHackettstownServices1 = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        locationHackettstownServices1 = all_services[:100] if len(all_services) >= 100 else all_services\n",
    "        with open(\"hackettstown_locations_services1.pkl\", \"wb\") as f:\n",
    "            pickle.dump(locationHackettstownServices1, f)\n",
    "        print(\"Created services1 pickle from retrieved data.\")\n",
    "\n",
    "try:\n",
    "    with open(\"hackettstown_locations_services2.pkl\", \"rb\") as f:\n",
    "        print(\"Loading services2 pickle...\")\n",
    "        locationHackettstownServices2 = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"services2 pickle missing; ensuring we have services data...\")\n",
    "    if all_services is None:\n",
    "        all_services = getBusinessLocations(soupHackettstownServices)\n",
    "    # create services2 from remaining links (if any)\n",
    "    locationHackettstownServices2 = all_services[100:] if len(all_services) > 100 else []\n",
    "    with open(\"hackettstown_locations_services2.pkl\", \"wb\") as f:\n",
    "        pickle.dump(locationHackettstownServices2, f)\n",
    "    print(\"Created services2 pickle from retrieved data.\")\n",
    "\n",
    "try:\n",
    "    with open(\"hackettstown_locations_shopping.pkl\", \"rb\") as f:\n",
    "        print(\"Loading pickle...\")\n",
    "        locationHackettstownShopping = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find file... attempting to retrieve data\")\n",
    "    locationHackettstownShopping = getBusinessLocations(soupHackettstownShopping)\n",
    "    print(\"Data retrieved! now adding to collection\")\n",
    "    with open(\"hackettstown_locations_shopping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(locationHackettstownShopping, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f182270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickle...\n",
      "[('40.8670057', '-74.8289007'), ('40.8533252', '-74.8323381'), ('40.8548488', '-74.833719'), ('40.8352012', '-74.8251916'), ('40.8459396', '-74.8270394'), ('40.838083', '-74.8262833'), ('40.8533252', '-74.8323381'), ('40.838083', '-74.8262833'), ('40.8528594', '-74.8310392'), ('40.8545017', '-74.8360921'), ('40.8542771', '-74.8323818'), ('40.8417021', '-74.8269408'), ('40.8670057', '-74.8289061'), ('40.8369845', '-74.8261737'), ('40.8414401', '-74.8268537'), ('40.8536627', '-74.8313182'), ('40.8338189', '-74.8272934'), ('40.8528594', '-74.8310392'), ('40.8421262', '-74.8268985'), ('40.8532575', '-74.8304141'), ('40.8509413', '-74.8285747'), ('40.8528536', '-74.831013'), ('40.8543675', '-74.8326537'), ('40.8546286', '-74.8381297'), ('40.8418207', '-74.8268222'), ('40.8380212', '-74.8263654'), ('40.8520302', '-74.8295963'), ('40.8407413', '-74.8259034'), ('40.8548578', '-74.835799'), ('40.8528357', '-74.8303754'), ('40.8507595', '-74.8289789'), ('40.8542383', '-74.8325206'), ('40.8549431', '-74.8497283'), ('40.8518104', '-74.8294181'), ('40.853353', '-74.8309315'), ('40.8546963', '-74.833373'), ('40.8542648', '-74.8325808'), ('40.8416993', '-74.8291171'), ('40.8580633', '-74.8311331'), ('40.8532516', '-74.8647472'), ('40.8510841', '-74.8260161'), ('40.8452684', '-74.826875'), ('40.8529454', '-74.8304705'), ('40.8534232', '-74.8306043'), ('40.859578', '-74.8181719'), ('40.859578', '-74.8181719'), ('40.8543675', '-74.8326537'), ('40.8553738', '-74.83504'), ('40.8436824', '-74.8271311'), ('40.8351913', '-74.8595247'), ('40.8510841', '-74.828591'), ('40.8453476', '-74.8270148'), ('40.8388749', '-74.8423953'), ('40.8409223', '-74.8426642'), ('40.8492117', '-74.8271228'), ('40.8382499', '-74.8255124'), ('40.8522069', '-74.830393'), ('40.852133', '-74.8298165')]\n"
     ]
    }
   ],
   "source": [
    "with open(\"hackettstown_locations_restaurants.pkl\", \"rb\") as f:\n",
    "        print(\"Loading pickle...\")\n",
    "        locationHackettstownRestaurants = pickle.load(f)\n",
    "print(getCoordinates(locationHackettstownRestaurants))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract coordinates from a list of Google Maps URLs\n",
    "\n",
    "def getCoordinates(locationHackettstown):\n",
    "    coordsHackettstown = []\n",
    "\n",
    "    #iterates through the lists of URLS\n",
    "    for i in range(len(locationHackettstown)):  # List to store the coordinates\n",
    "\n",
    "        #finds a match of the regex withen each item from locationHackettstown\n",
    "        match = re.search(r'@(-?\\d+(?:\\.\\d+)?),(-?\\d+(?:\\.\\d+)?)', locationHackettstown[i])\n",
    "        if not match:\n",
    "            print(f\"No coordinates found in URL: {locationHackettstown[i]}\")\n",
    "        if match:\n",
    "            latitudeLocation = match.group(1) #makes a variable for the latitude based off of a regex grouping\n",
    "            longitudeLocation = match.group(2) #makes a variable for the longitude based off of a regex grouping\n",
    "        coordsHackettstown.append((latitudeLocation, longitudeLocation)) # appends the coordinates to the list as a tuple\n",
    "        \n",
    "    return coordsHackettstown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c59a7d",
   "metadata": {},
   "source": [
    "# Part 4: Creating a pandas Dataframe to store the location and business names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this I will create indavidual dataframes for each category of location, further to combine the data later, I will be using data flattening methods.\n",
    "namesHackettstownRestaurants = namesHackettstownRestaurants\n",
    "dataRestaurants = pd.DataFrame({\n",
    "    'Name': namesHackettstownRestaurants,\n",
    "    'Latitude': [coord[0] for coord in coordinateHackettstownRestaurants],\n",
    "    'Longitude': [coord[1] for coord in coordinateHackettstownRestaurants]\n",
    "})\n",
    "dataShopping = pd.DataFrame({\n",
    "    'Name': namesHackettstownShopping,\n",
    "    'Latitude': [coord[0] for coord in coordinateHackettstownShopping],\n",
    "    'Longitude': [coord[1] for coord in coordinateHackettstownShopping]\n",
    "})\n",
    "dataServices = pd.DataFrame({\n",
    "    'Name': namesHackettstownServices,\n",
    "    'Latitude': [coord[0] for coord in coordinateHackettstownServices],\n",
    "    'Longitude': [coord[1] for coord in coordinateHackettstownServices]\n",
    "})\n",
    "dataEntertainmentGaming = pd.DataFrame({\n",
    "    'Name': namesHackettstownEntertainmentGaming,\n",
    "    'Latitude': [coord[0] for coord in coordinateHackettstownEntertainmentGaming],\n",
    "    'Longitude': [coord[1] for coord in coordinateHackettstownEntertainmentGaming]\n",
    "})\n",
    "dataCommunity = pd.DataFrame({\n",
    "    'Name': namesHackettstownCommunity,\n",
    "    'Latitude': [coord[0] for coord in coordinateHackettstownCommunity],\n",
    "    'Longitude': [coord[1] for coord in coordinateHackettstownCommunity]\n",
    "})\n",
    "\n",
    "print(dataRestaurants)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
